# API de Predicci√≥n de Adherencia de Pacientes Oncol√≥gicos

[![CI/CD Pipeline](https://github.com/USUARIO/REPO/actions/workflows/ci-cd.yml/badge.svg)](https://github.com/USUARIO/REPO/actions/workflows/ci-cd.yml)
[![Docker](https://img.shields.io/badge/docker-ghcr.io-blue)](https://github.com/USUARIO/REPO/pkgs/container/REPO)
[![Python](https://img.shields.io/badge/python-3.13-blue)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.115+-green)](https://fastapi.tiangolo.com/)

## üìã Descripci√≥n del Proyecto

API desarrollada con FastAPI para predecir la adherencia a tratamientos de pacientes oncol√≥gicos utilizando Machine Learning. El sistema procesa datos de consultas m√©dicas y resultados de laboratorio para generar predicciones mediante modelos de XGBoost y Redes Neuronales.

---

## üéØ Soluci√≥n a la Prueba T√©cnica

Este proyecto resuelve los siguientes requerimientos del examen t√©cnico:

### **Parte 1: Ingenier√≠a de Datos**

#### **a) Bases de datos: Consulta de informaci√≥n consolidada por paciente**

**Endpoint:** `GET /laboratorio/dataset`

```bash
curl -X GET "http://localhost:8000/laboratorio/dataset" \
     -H "accept: application/json"
```

**Descripci√≥n:** Retorna un dataset consolidado que incluye:

- Informaci√≥n del paciente (demograf√≠a y diagn√≥stico)
- N√∫mero total de consultas por paciente
- N√∫mero total de laboratorios por paciente
- Promedio de resultados num√©ricos por tipo de prueba (biopsia, VPH, CA125, PSA, colonoscopia)

**Respuesta:** Array de objetos con toda la informaci√≥n consolidada por paciente.

---

#### **b) Procesamiento de datos: Limpieza y normalizaci√≥n**

**Endpoint:** `PUT /laboratorio/procesamiento/limpieza`

```bash
curl -X PUT "http://localhost:8000/laboratorio/procesamiento/limpieza" \
     -H "accept: application/json"
```

**Descripci√≥n:** Ejecuta un pipeline de limpieza que incluye:

- ‚úÖ Normalizaci√≥n de texto (min√∫sculas, eliminaci√≥n de tildes)
- ‚úÖ Estandarizaci√≥n de valores categ√≥ricos
- ‚úÖ Correcci√≥n de outliers en resultados num√©ricos mediante Winsorizaci√≥n (IQR)
- ‚úÖ **Imputaci√≥n inteligente de valores faltantes:**
  - Columnas con < 5% faltantes: Valores por defecto o mediana/moda
  - Columnas con 5-20% faltantes: Mediana (num√©ricos) o moda (categ√≥ricos)
  - Columnas con > 20% faltantes: Imputaci√≥n con 0 para columnas num√©ricas
- ‚úÖ Validaci√≥n de tipos de datos
- ‚úÖ **Garant√≠a de datos sin NaN** - Los valores nulos se imputan directamente en la base de datos

**Respuesta:** Reporte detallado con:

- Total de registros procesados por tabla
- Cambios realizados (normalizaciones, imputaciones, correcciones)
- An√°lisis detallado de valores faltantes con recomendaciones
- Outliers detectados y corregidos
- Tiempo de procesamiento

**‚ö†Ô∏è Importante:** Este endpoint debe ejecutarse **antes** de generar el dataset de modelado para garantizar que los datos est√©n completamente limpios.

---

#### **c) Dataset para modelado: Generaci√≥n de dataset listo para ML**

**Endpoint:** `GET /laboratorio/dataset/modelado`

```bash
curl -X GET "http://localhost:8000/laboratorio/dataset/modelado" \
     -H "accept: application/json"
```

**Descripci√≥n:** Genera un dataset optimizado para Machine Learning:

- ‚úÖ Una fila por paciente
- ‚úÖ Todas las variables agregadas (conteos, promedios por tipo de prueba)
- ‚úÖ **Sin valores nulos** - Datos completamente limpios desde la base de datos
- ‚úÖ Tipos de datos correctos (num√©ricos como float, categ√≥ricos como string)
- ‚úÖ Guardado como CSV con timestamp en `./data/dataset_modelado_YYYYMMDD_HHMMSS.csv`
- ‚úÖ **Manejo robusto de NaN** - Valores `nan` de SQL se convierten autom√°ticamente a 0.0

**Flujo recomendado:**

1. Cargar datos desde Excel: `POST /laboratorio/datos`
2. Ejecutar limpieza: `PUT /laboratorio/procesamiento/limpieza`
3. Generar dataset: `GET /laboratorio/dataset/modelado` ‚Üê Este endpoint

**Respuesta:**

```json
{
  "ruta_archivo": "./data/dataset_modelado_YYYYMMDD_HHMMSS.csv",
  "total_registros": 1000,
  "descripcion": "Dataset consolidado con 1000 pacientes. Incluye: datos demogr√°ficos, cl√≠nicos, conteos de consultas/laboratorios, y promedios de resultados por tipo de prueba. Listo para modelado de Machine Learning."
}
```

---

### **Parte 2: Machine Learning**

#### **a) Entrenamiento de modelos**

**Endpoint:** `POST /laboratorio/modelado/entrenar`

```bash
# Entrenar modelo XGBoost (Gradient Boosting)
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "xgboost"}'

# Entrenar modelo de Red Neuronal (TensorFlow)
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "neural_network"}'
```

**Descripci√≥n:** Entrena modelos de predicci√≥n de adherencia:

- **XGBoost**: Modelo basado en HistGradientBoostingClassifier de scikit-learn
- **Neural Network**: Red neuronal profunda con TensorFlow/Keras

**Proceso autom√°tico:**

1. Carga del dataset m√°s reciente de `./data/`
2. Codificaci√≥n de variables categ√≥ricas (Label Encoding)
3. Split 80/20 (entrenamiento/test)
4. Entrenamiento del modelo
5. Evaluaci√≥n con m√©tricas est√°ndar
6. Guardado autom√°tico en `./models/` con timestamp

**Respuesta:** M√©tricas completas del modelo

```json
{
  "modelo": "xgboost",
  "metricas_train": {
    "accuracy": 0.95,
    "precision": 0.94,
    "recall": 0.96,
    "f1_score": 0.95,
    "auc": 0.97
  },
  "metricas_test": {
    "accuracy": 0.92,
    "precision": 0.91,
    "recall": 0.93,
    "f1_score": 0.92,
    "auc": 0.94
  },
  "tiempo_entrenamiento": 45.23,
  "total_registros": 1000,
  "features_utilizados": 14,
  "fecha_entrenamiento": "2024-11-17T23:12:43"
}
```

---

#### **b) Predicci√≥n de adherencia**

**Endpoint:** `POST /laboratorio/predecir`

```bash
curl -X POST "http://localhost:8000/laboratorio/predecir" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{
  "tipo_modelo": "xgboost",
  "sexo": "Femenino",
  "edad": 55,
  "zona_residencia": "Urbana",
  "tipo_cancer": "Mama",
  "estadio": "Ii",
  "aseguradora": "Sura",
  "count_consultas": 12,
  "dias_desde_diagnostico": 365,
  "count_laboratorios": 8,
  "avg_resultado_numerico": 2.5,
  "avg_biopsia": 0.0,
  "avg_vpH": 0.0,
  "avg_marcador_ca125": 45.3,
  "avg_psa": 0.0,
  "avg_colonoscopia": 0.0
}'
```

**Descripci√≥n:** Predice la adherencia a 12 meses de un paciente usando el modelo especificado.

**Par√°metros:**

- `tipo_modelo`: `"xgboost"` o `"neural_network"`
- Datos demogr√°ficos: sexo, edad, zona_residencia
- Datos cl√≠nicos: tipo_cancer, estadio, aseguradora
- Variables agregadas: conteos de consultas/laboratorios, promedios de resultados

**Respuesta:**

```json
{
  "prediction": 1,
  "probability": 0.87,
  "model_version": "xgboost_20241117_231152",
  "model_name": "xgboost",
  "inference_time_ms": 15.43
}
```

- `prediction`: 0 = No adherente, 1 = Adherente
- `probability`: Probabilidad de adherencia (0.0 a 1.0)

---

#### **c) Evaluaci√≥n con m√©tricas t√©cnicas**

Las m√©tricas de **accuracy, precision, recall, F1-Score y AUC** se calculan autom√°ticamente durante el entrenamiento y se retornan en la respuesta del endpoint `POST /laboratorio/modelado/entrenar`. Cada modelo incluye m√©tricas tanto para el conjunto de entrenamiento (`metricas_train`) como para el conjunto de test (`metricas_test`).

**Ver secci√≥n (d) Comparaci√≥n de Modelos** m√°s abajo para los resultados completos.

---

#### **d) Comparaci√≥n de Modelos**

**Resultados del entrenamiento (80 registros, datos limpios):**

| M√©trica | XGBoost | Neural Network |
|---------|---------|----------------|
| Accuracy Test | **81.25%** | 68.75% |
| F1-Score Test | **0.88** | 0.78 |
| AUC Test | **0.60** | 0.58 |
| Tiempo Entrenamiento | ~0.2s | ~8s |
| Inference Time | **~5ms** | ~15ms |

**¬øCu√°l funciona mejor?**

**XGBoost** supera a la red neuronal en todas las m√©tricas. Con 81.25% de accuracy vs 68.75%, XGBoost demuestra mejor capacidad para aprender patrones con datasets peque√±os (< 1000 registros). Los modelos basados en √°rboles de decisi√≥n son m√°s robustos con datos limitados, mientras que las redes neuronales requieren mayor cantidad de ejemplos para generalizar correctamente.

**Impacto de la limpieza de datos:**

- XGBoost mejor√≥ de 68% a **81.25%** (+13%) gracias a la imputaci√≥n de NaN
- Neural Network mejor√≥ de 31% a **68.75%** (+37%) al eliminar valores faltantes

**¬øCu√°l es m√°s f√°cil de desplegar?**

**XGBoost** es significativamente m√°s sencillo:

- **Artifact √∫nico:** 1 archivo `.pkl` (~100KB) vs modelo `.keras` + scaler `.pkl`
- **Dependencias ligeras:** scikit-learn (~50MB) vs TensorFlow (~500MB)
- **Velocidad:** 3x m√°s r√°pido en inferencia (5ms vs 15ms)
- **Recursos:** ~50MB RAM vs ~200MB RAM
- **Compatibilidad:** Cualquier servidor Python, sin necesidad de GPU

**Recomendaci√≥n:** Para este caso de uso con datos limitados y requisitos de producci√≥n, **XGBoost es la mejor opci√≥n** tanto en rendimiento (81% accuracy) como en facilidad de deployment. La red neuronal solo se justificar√≠a con >1000 registros de entrenamiento.

---

### **Parte 3: An√°lisis y Visualizaci√≥n**

#### **Dashboard por tipo de c√°ncer**

**Endpoint:** `GET /laboratorio/dashboard/{tipo_cancer}`

```bash
curl -X GET "http://localhost:8000/laboratorio/dashboard/Mama" \
     -H "accept: application/json"
```

**Descripci√≥n:** Retorna estad√≠sticas agregadas para un tipo espec√≠fico de c√°ncer:

- Total de pacientes
- Distribuci√≥n por estadio
- Tasa de adherencia
- Promedios de edad
- Distribuci√≥n por aseguradora
- Estad√≠sticas de consultas y laboratorios

---

#### **Pacientes con actividad reciente**

**Endpoint:** `GET /laboratorio/pacientes/activos`

```bash
curl -X GET "http://localhost:8000/laboratorio/pacientes/activos?dias=30" \
     -H "accept: application/json"
```

**Descripci√≥n:** Lista pacientes con consultas o laboratorios en los √∫ltimos N d√≠as.

---

#### **An√°lisis de laboratorios por paciente**

**Endpoint:** `GET /laboratorio/analisis/paciente/{id_paciente}`

```bash
curl -X GET "http://localhost:8000/laboratorio/analisis/paciente/PAC001" \
     -H "accept: application/json"
```

**Descripci√≥n:** An√°lisis detallado de resultados de laboratorio de un paciente espec√≠fico.

---

## üîÑ CI/CD Pipeline

Pipeline automatizado con GitHub Actions:

- ‚úÖ **Ruff**: Validaci√≥n de c√≥digo
- ‚úÖ **Pyright**: Type checking
- üê≥ **Docker Build**: Construcci√≥n autom√°tica
- üì¶ **Registry**: Publicaci√≥n en ghcr.io

### Pull de la imagen

```bash
docker pull ghcr.io/TU_USUARIO/test-inc:latest
```

---

## üöÄ Instalaci√≥n y Configuraci√≥n

### Opci√≥n 1: Docker (Recomendado)

#### 1. Crear archivo `.env`

```bash
DB_USERNAME=postgres
DB_PASSWORD=postgres123
DB_HOST=localhost
DB_PORT=5432
DB_NAME=adherencia_db
```

#### 2. Iniciar servicios

```bash
# Construir y levantar contenedores
docker-compose up --build

# En modo background
docker-compose up -d --build
```

**¬øQu√© hace Docker Compose?**

1. ‚úÖ Inicia PostgreSQL con la base de datos
2. ‚úÖ Espera a que PostgreSQL est√© listo (health check)
3. ‚úÖ Ejecuta migraciones de Alembic autom√°ticamente
4. ‚úÖ Inicia la API en el puerto 8000

La API estar√° disponible en: <http://localhost:8000>

---

### Opci√≥n 2: Instalaci√≥n Local

#### 1. Instalar dependencias

```bash
# Usando uv (recomendado)
pip install uv
uv pip install -r pyproject.toml

# O usando pip directamente
pip install -e .
```

#### 2. Configurar base de datos

Editar `.env` con las credenciales de PostgreSQL local.

#### 3. Ejecutar migraciones

```bash
alembic upgrade head
```

#### 4. Iniciar la API

```bash
python -m uvicorn src.main:app --host 0.0.0.0 --port 8000 --reload
```

---

## üìä Flujo de Trabajo Completo

Para resolver la prueba t√©cnica, sigue este flujo **en orden**:

### 0Ô∏è‚É£ **Cargar Datos Iniciales** (Si la BD est√° vac√≠a)

```bash
# Subir archivo Excel con datos
curl -X POST "http://localhost:8000/laboratorio/datos" \
     -F "file=@./data/Dataset_prueba.xlsx"
```

**Resultado esperado:** ‚úì 80 pacientes, 596 consultas, 430 laboratorios

### 1Ô∏è‚É£ **Procesar y Limpiar Datos** ‚ö†Ô∏è CR√çTICO

```bash
# Limpiar, normalizar e imputar valores faltantes
curl -X PUT "http://localhost:8000/laboratorio/procesamiento/limpieza"
```

**¬øPor qu√© es cr√≠tico?**

- Imputa ~228 registros con NaN en `resultado_numerico` (53% de los datos)
- Normaliza variables categ√≥ricas
- Corrige outliers en datos num√©ricos
- **Garantiza dataset 100% limpio para ML**

**Resultado esperado:** ‚úì Reporte con imputaciones realizadas

### 2Ô∏è‚É£ **Generar Dataset para Modelado**

```bash
# Crear dataset optimizado para ML (usa datos limpios de paso 1)
curl -X GET "http://localhost:8000/laboratorio/dataset/modelado"
```

**Resultado esperado:** ‚úì CSV sin valores vac√≠os en `./data/dataset_modelado_YYYYMMDD_HHMMSS.csv`

### 3Ô∏è‚É£ **Entrenar Modelos**

```bash
# Entrenar XGBoost
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "xgboost"}'

# Entrenar Red Neuronal
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "neural_network"}'
```

### 4Ô∏è‚É£ **Realizar Predicciones**

```bash
# Predecir adherencia de un paciente con XGBoost
curl -X POST "http://localhost:8000/laboratorio/predecir" \
     -H "Content-Type: application/json" \
     -d '{
  "tipo_modelo": "xgboost",
  "sexo": "Femenino",
  "edad": 55,
  "zona_residencia": "Urbana",
  "tipo_cancer": "Mama",
  "estadio": "Ii",
  "aseguradora": "Sura",
  "count_consultas": 12,
  "dias_desde_diagnostico": 365,
  "count_laboratorios": 8,
  "avg_resultado_numerico": 2.5,
  "avg_biopsia": 0.0,
  "avg_vpH": 0.0,
  "avg_marcador_ca125": 45.3,
  "avg_psa": 0.0,
  "avg_colonoscopia": 0.0
}'
```

**Resultado esperado:**

```json
{
  "prediction": 1,
  "probability": 0.6094,
  "model_version": "xgboost_20251118_000450",
  "model_name": "xgboost",
  "inference_time_ms": 5.44
}
```

**Nota:** Cambia `"tipo_modelo"` a `"neural_network"` para usar el modelo de red neuronal.

---

## üìö Documentaci√≥n Interactiva

Una vez iniciada la API, accede a:

- **Swagger UI**: <http://localhost:8000/docs>
- **ReDoc**: <http://localhost:8000/redoc>
- **Health Check**: <http://localhost:8000/health>

La documentaci√≥n interactiva permite:

- üîç Explorar todos los endpoints
- üìù Ver esquemas de request/response
- ‚ñ∂Ô∏è Probar endpoints directamente desde el navegador
- üìñ Leer descripciones detalladas de cada operaci√≥n

---

## üèóÔ∏è Arquitectura del Proyecto

```
Test-INC/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Aplicaci√≥n principal FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tables.py              # Modelos SQLModel (ORM)
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # Endpoints de datos y procesamiento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference.py           # Endpoints de ML y predicci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # L√≥gica de procesamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py           # L√≥gica de ML y predicci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.py          # Monitoreo de predicciones
‚îÇ   ‚îú‚îÄ‚îÄ app_types/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # Tipos para datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py           # Tipos para ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.py          # Tipos para monitoreo
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ settings.py            # Configuraci√≥n y variables de entorno
‚îÇ       ‚îî‚îÄ‚îÄ logging_config.py      # Configuraci√≥n de logging
‚îú‚îÄ‚îÄ alembic/                       # Migraciones de base de datos
‚îú‚îÄ‚îÄ models/                        # Modelos ML entrenados (*.pkl, *.keras)
‚îú‚îÄ‚îÄ data/                          # Datasets generados (*.csv)
‚îú‚îÄ‚îÄ logs/                          # Logs de la aplicaci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml             # Configuraci√≥n Docker Compose
‚îú‚îÄ‚îÄ Dockerfile                     # Imagen Docker de la API
‚îú‚îÄ‚îÄ entrypoint.sh                  # Script de inicio (ejecuta migraciones)
‚îî‚îÄ‚îÄ pyproject.toml                 # Dependencias del proyecto
```

---

## üîß Stack Tecnol√≥gico

### Backend

- **FastAPI** 0.115+: Framework web moderno y r√°pido
- **Python** 3.13: Lenguaje de programaci√≥n
- **SQLModel**: ORM para PostgreSQL
- **Pydantic**: Validaci√≥n de datos
- **Alembic**: Migraciones de base de datos

### Machine Learning

- **scikit-learn**: Preprocesamiento y XGBoost
- **TensorFlow/Keras**: Redes Neuronales
- **pandas**: Manipulaci√≥n de datos
- **numpy**: Computaci√≥n num√©rica

### Base de Datos

- **PostgreSQL** 17: Base de datos relacional
- **psycopg3**: Driver de PostgreSQL

### DevOps

- **Docker**: Contenedorizaci√≥n
- **Docker Compose**: Orquestaci√≥n de servicios
- **uv**: Gestor de paquetes de Python

---

## üìà Modelos de Machine Learning

### XGBoost (HistGradientBoostingClassifier)

- **Algoritmo**: Gradient Boosting optimizado
- **Ventajas**: R√°pido, maneja datos desbalanceados, robusto
- **Hiperpar√°metros**:
  - `max_depth`: 10
  - `learning_rate`: 0.1
  - `n_estimators`: 100

### Red Neuronal (TensorFlow)

- **Arquitectura**:
  - Input layer: 14 features
  - Hidden layers: [128, 64, 32] neuronas con ReLU
  - Dropout: 0.3 para regularizaci√≥n
  - Output layer: 1 neurona con sigmoid
- **Optimizador**: Adam
- **Loss**: Binary Crossentropy
- **Epochs**: 50 con early stopping

### Preprocesamiento

- **Label Encoding** para variables categ√≥ricas (`zona_residencia`, `tipo_cancer`)
- **StandardScaler** para normalizaci√≥n de features num√©ricas (solo Neural Network)
- **Imputaci√≥n autom√°tica de NaN** durante entrenamiento (fallback de seguridad)
- **Correcci√≥n de outliers** mediante Winsorizaci√≥n en el endpoint de limpieza
- **Orden correcto de features** - Se preserva el orden de columnas usado durante entrenamiento

**Nota:** La imputaci√≥n durante entrenamiento es un fallback. Los datos deber√≠an estar limpios desde el endpoint `/limpieza`.

---

## üìä M√©tricas de Evaluaci√≥n

Los modelos se eval√∫an con:

- **Accuracy**: Precisi√≥n general
- **Precision**: Verdaderos positivos / (VP + FP)
- **Recall**: Verdaderos positivos / (VP + FN)
- **F1-Score**: Media arm√≥nica de precision y recall
- **AUC-ROC**: √Årea bajo la curva ROC

---

## üê≥ Docker: Detalles T√©cnicos

### Servicios

#### PostgreSQL

- **Imagen**: `postgres:17-alpine`
- **Puerto**: 5432
- **Volumen persistente**: `postgres_data`
- **Health check**: `pg_isready`

#### API FastAPI

- **Base**: `python:3.13-slim`
- **Puerto**: 8000
- **Vol√∫menes montados**:
  - `./models`: Modelos entrenados
  - `./data`: Datasets CSV
  - `./logs`: Logs de aplicaci√≥n

### Flujo de Inicio

```
1. docker-compose up
   ‚Üì
2. PostgreSQL inicia y pasa health check
   ‚Üì
3. API espera a PostgreSQL (depends_on: service_healthy)
   ‚Üì
4. entrypoint.sh ejecuta:
   - Espera conexi√≥n a PostgreSQL
   - Corre: alembic upgrade head
   - Inicia: uvicorn
   ‚Üì
5. API lista en http://localhost:8000
```

---

## üß™ Testing

### Test Manual con curl

Ver ejemplos de curl en cada secci√≥n de endpoints arriba.

### Test con Swagger UI

1. Abrir <http://localhost:8000/docs>
2. Expandir el endpoint deseado
3. Clic en "Try it out"
4. Llenar par√°metros
5. Clic en "Execute"

### Test Automatizado

```bash
# Ejecutar tests (si est√°n disponibles)
pytest test/
```

---

## üìù Logging y Monitoreo

### Logs

Los logs se guardan en:

- **Consola**: Nivel INFO
- **Archivo**: `logs/app.log` con nivel DEBUG

### Monitoreo de Predicciones

Cada predicci√≥n se registra autom√°ticamente con:

- Request ID √∫nico
- Versi√≥n del modelo
- Predicci√≥n y probabilidad
- Tiempo de inferencia
- Features de entrada
- Estado de √©xito/error

---

## ‚ö†Ô∏è Troubleshooting

### Error: "No se encontr√≥ ning√∫n modelo"

**Soluci√≥n**: Entrenar un modelo primero usando el endpoint de entrenamiento.

### Error: "Dataset no encontrado"

**Soluci√≥n**: Generar el dataset primero usando `GET /laboratorio/dataset/modelado`.

### Error de conexi√≥n a PostgreSQL

**Soluci√≥n**:

1. Verificar que Docker Compose est√° corriendo
2. Revisar credenciales en `.env`
3. Verificar logs: `docker-compose logs postgres`

### Puerto 8000 ocupado

**Soluci√≥n**:

```bash
# Ver qu√© proceso usa el puerto
sudo lsof -i :8000
# Cambiar puerto en docker-compose.yml o matar el proceso
```

---

## üîß Mejoras T√©cnicas Implementadas

### Manejo Robusto de Valores NaN

El sistema implementa un enfoque de m√∫ltiples capas para garantizar datos limpios:

#### 1. **Limpieza en la Fuente** (`/laboratorio/procesamiento/limpieza`)

- Imputa valores NaN directamente en la base de datos
- Estrategia adaptativa seg√∫n porcentaje de valores faltantes
- Columnas num√©ricas con >20% faltantes: Imputaci√≥n con 0 (antes se rechazaba)
- Ejemplo: `resultado_numerico` con 53% faltantes ‚Üí 228 registros imputados con 0

#### 2. **Generaci√≥n de Dataset** (`/laboratorio/dataset/modelado`)

- Detecci√≥n de valores `nan` de tipo float retornados por SQL
- Conversi√≥n autom√°tica mediante funci√≥n `safe_float()` que maneja:
  - `None` ‚Üí 0.0
  - `float('nan')` ‚Üí 0.0
  - Valores v√°lidos ‚Üí preservados
- Verificaci√≥n final con `df.fillna(0)` como fallback

#### 3. **Entrenamiento de Modelos**

- Imputaci√≥n adicional durante entrenamiento (fallback de seguridad)
- Preservaci√≥n del orden de features entre entrenamiento y predicci√≥n
- Guardado de `label_encoders` y `feature_names` con cada modelo

#### 4. **Predicciones**

- Codificaci√≥n correcta de variables categ√≥ricas a `*_encoded`
- Orden garantizado de columnas usando metadata del modelo
- Manejo de valores desconocidos en encoding (fallback a 0)

### Resultados de las Mejoras

**Antes:**

- Dataset con campos vac√≠os (`,,`)
- Warnings de imputaci√≥n durante entrenamiento
- Accuracy ~68%

**Despu√©s:**

- Dataset 100% sin valores vac√≠os ‚úÖ
- Sin warnings de NaN ‚úÖ
- Accuracy ~81% ‚úÖ (mejora del 13%)
- Pipeline completo sin errores ‚úÖ

### Acceso a Datos SQL

El sistema usa `text()` de SQLAlchemy para queries complejas. Se implement√≥:

- Acceso por √≠ndice (`row[0]`, `row[1]`) en lugar de atributos
- Compatible con resultados de tipo tupla
- Aplicado en endpoints:
  - `/laboratorio/analisis/dias-lab-diagnostico`
  - `/laboratorio/dataset/modelado`

---

## üë®‚Äçüíª Desarrollo

### Agregar dependencias

```bash
# Agregar al pyproject.toml y ejecutar:
uv pip install -r pyproject.toml
```

### Crear nueva migraci√≥n

```bash
# Despu√©s de modificar models/tables.py
alembic revision --autogenerate -m "descripci√≥n del cambio"
alembic upgrade head
```

### Validaci√≥n de c√≥digo

```bash
# Type checking
pyright src/

# Linting
ruff check src/
```

---

## üìÑ Licencia

Este proyecto fue desarrollado como prueba t√©cnica para el Laboratorio de Cocreaci√≥n.

---

## ü§ù Contacto

Para dudas sobre la implementaci√≥n o prueba t√©cnica, contactar al equipo de desarrollo.

---

## üéØ Checklist de Entrega

- ‚úÖ Base de datos PostgreSQL con esquema definido
- ‚úÖ Endpoints de consulta y agregaci√≥n de datos
- ‚úÖ Pipeline de limpieza y procesamiento de datos
- ‚úÖ Generaci√≥n de dataset para modelado
- ‚úÖ Entrenamiento de modelo XGBoost
- ‚úÖ Entrenamiento de Red Neuronal
- ‚úÖ Endpoint de predicci√≥n con ambos modelos
- ‚úÖ Documentaci√≥n interactiva (Swagger)
- ‚úÖ Docker Compose funcional
- ‚úÖ Migraciones autom√°ticas con Alembic
- ‚úÖ Logging y monitoreo de predicciones
- ‚úÖ C√≥digo validado (pyright + ruff)
- ‚úÖ README completo con ejemplos

---

**¬°API lista para demostraci√≥n! üöÄ**
