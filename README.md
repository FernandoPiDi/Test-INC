# API de Predicci√≥n de Adherencia de Pacientes Oncol√≥gicos

## Descripci√≥n del Proyecto

API desarrollada con FastAPI para predecir la adherencia a tratamientos de pacientes oncol√≥gicos utilizando Machine Learning. El sistema procesa los datos de consultas m√©dicas y resultados de laboratorio para generar predicciones mediante modelos de XGBoost y Redes Neuronales.

---

## Instalaci√≥n y Configuraci√≥n

### Docker

#### 1. Crear archivo `.env`

```bash
DB_USERNAME=postgres
DB_PASSWORD=postgres123
DB_HOST=localhost
DB_PORT=5432
DB_NAME=adherencia_db
```

#### 2. Iniciar servicios

```bash
# Construir y levantar contenedores
docker-compose up --build

# En modo background
docker-compose up -d --build
```

**¬øQu√© hace Docker Compose?**

1. Inicia PostgreSQL con la base de datos
2. Espera a que PostgreSQL est√© listo (health check)
3. Ejecuta migraciones de Alembic autom√°ticamente
4. Inicia la API en el puerto 8000

La API estar√° disponible en: <http://localhost:8000>

## Flujo de Trabajo Completo para la API

### **Cargar Datos Iniciales** (Si la BD est√° vac√≠a)

```bash
# Subir archivo Excel con datos
curl -X POST "http://localhost:8000/laboratorio/datos" \
     -F "file=@./data/Dataset_prueba.xlsx"
```

**Resultado esperado:**  80 pacientes, 596 consultas, 430 laboratorios

### **Procesar y Limpiar Datos**

```bash
# Limpiar, normalizar e imputar valores faltantes
curl -X PUT "http://localhost:8000/laboratorio/procesamiento/limpieza"
```

¬øPor qu√© es cr√≠tico?

- Imputa ~228 registros con NaN en `resultado_numerico` (53% de los datos)
- Normaliza variables categ√≥ricas
- Corrige outliers en datos num√©ricos
- Garantiza dataset 100% limpio para ML

Resultado esperado: Reporte con imputaciones realizadas

### **Generar Dataset para Modelado**

```bash
# Crear dataset optimizado para ML (usa datos limpios de paso 1)
curl -X GET "http://localhost:8000/laboratorio/dataset/modelado"
```

Resultado esperado: ‚úì CSV sin valores vac√≠os en `./data/dataset_modelado_YYYYMMDD_HHMMSS.csv`

### **Entrenar Modelos**

```bash
# Entrenar XGBoost
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "xgboost"}'

# Entrenar Red Neuronal
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "neural_network"}'
```

### **Realizar Predicciones**

```bash
# Predecir adherencia de un paciente con XGBoost
curl -X POST "http://localhost:8000/laboratorio/predecir" \
     -H "Content-Type: application/json" \
     -d '{
  "tipo_modelo": "xgboost",
  "sexo": "Femenino",
  "edad": 55,
  "zona_residencia": "Urbana",
  "tipo_cancer": "Mama",
  "estadio": "Ii",
  "aseguradora": "Sura",
  "count_consultas": 12,
  "dias_desde_diagnostico": 365,
  "count_laboratorios": 8,
  "avg_resultado_numerico": 2.5,
  "avg_biopsia": 0.0,
  "avg_vpH": 0.0,
  "avg_marcador_ca125": 45.3,
  "avg_psa": 0.0,
  "avg_colonoscopia": 0.0
}'
```

Resultado esperado:

```json
{
  "prediction": 1,
  "probability": 0.6094,
  "model_version": "xgboost_20251118_000450",
  "model_name": "xgboost",
  "inference_time_ms": 5.44
}
```

**Nota:** Cambia `"tipo_modelo"` a `"neural_network"` para usar el modelo de red neuronal.

---

## Soluci√≥n a la Prueba T√©cnica

Este proyecto resuelve los siguientes requerimientos del examen t√©cnico:

### **Parte 1: Ingenier√≠a de Datos**

La implementaci√≥n sigue un proceso ETL (Extract, Transform, Load) cl√°sico aplicado a datos m√©dicos:

- **Extract (Extraer)**: `POST /laboratorio/datos` - Subir y cargar archivos Excel con datos crudos
- **Transform (Transformar)**: `PUT /laboratorio/procesamiento/limpieza` - Limpiar, normalizar y estandarizar datos
- **Load (Cargar)**: `GET /laboratorio/dataset/modelado` - Generar datasets optimizados listos para an√°lisis y modelos

Este flujo garantiza que los datos m√©dicos sean confiables y est√©n preparados para generar insights precisos.

#### **a) Bases de datos:**

**Endpoint:** `GET /laboratorio/dataset`

```bash
curl -X GET "http://localhost:8000/laboratorio/dataset" \
     -H "accept: application/json"
```

**Query SQL - Extract (Carga de datos desde Excel):**

```sql
-- Los datos se cargan desde Excel usando pandas.read_excel()
-- y se insertan en las tablas usando SQLAlchemy ORM

INSERT INTO paciente (
    id_paciente, sexo, edad, zona_residencia, fecha_dx,
    tipo_cancer, estadio, aseguradora, adherencia_12m
) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?);

INSERT INTO consulta (
    id_consulta, id_paciente, fecha_consulta, motivo,
    prioridad, especialista
) VALUES (?, ?, ?, ?, ?, ?);

INSERT INTO laboratorio (
    id_lab, id_paciente, fecha_muestra, tipo_prueba,
    resultado, resultado_numerico, unidad
) VALUES (?, ?, ?, ?, ?, ?, ?);
```

**Descripci√≥n:** Retorna un dataset consolidado que incluye:

- Informaci√≥n del paciente (demograf√≠a y diagn√≥stico)
- N√∫mero total de consultas por paciente
- N√∫mero total de laboratorios por paciente
- Promedio de resultados num√©ricos por tipo de prueba (biopsia, VPH, CA125, PSA, colonoscopia)

**Respuesta:** Array de objetos con toda la informaci√≥n consolidada por paciente.

---

#### **b) Procesamiento de datos: Limpieza y normalizaci√≥n**

**Endpoint:** `PUT /laboratorio/procesamiento/limpieza`

```bash
curl -X PUT "http://localhost:8000/laboratorio/procesamiento/limpieza" \
     -H "accept: application/json"
```

**Descripci√≥n:** Ejecuta un pipeline de limpieza que incluye:

- Normalizaci√≥n de texto (min√∫sculas, eliminaci√≥n de tildes)
- Estandarizaci√≥n de valores categ√≥ricos
- Correcci√≥n de outliers en resultados num√©ricos mediante Winsorizaci√≥n (IQR)
- Imputaci√≥n inteligente de valores faltantes:
  - Columnas con < 5% faltantes: Valores por defecto o mediana/moda
  - Columnas con 5-20% faltantes: Mediana (num√©ricos) o moda (categ√≥ricos)
  - Columnas con > 20% faltantes: Imputaci√≥n con 0 para columnas num√©ricas
- Validaci√≥n de tipos de datos
- Garant√≠a de datos sin NaN - Los valores nulos se imputan directamente en la base de datos

Respuesta: Reporte detallado con:

- Total de registros procesados por tabla
- Cambios realizados (normalizaciones, imputaciones, correcciones)
- An√°lisis detallado de valores faltantes con recomendaciones
- Outliers detectados y corregidos
- Tiempo de procesamiento

**Importante:** Este endpoint debe ejecutarse **antes** de generar el dataset de modelado para garantizar que los datos est√©n completamente limpios.

**Query SQL - Transform (Carga de datos para limpieza):**

```sql
-- Datos se cargan desde BD a pandas para procesamiento
SELECT * FROM paciente;
SELECT * FROM consulta;
SELECT * FROM laboratorio;
```

---

#### **c) Dataset para modelado: Generaci√≥n de dataset listo para ML**

**Endpoint:** `GET /laboratorio/dataset/modelado`

```bash
curl -X GET "http://localhost:8000/laboratorio/dataset/modelado" \
     -H "accept: application/json"
```

**Descripci√≥n:** Genera un dataset optimizado para Machine Learning:

- Una fila por paciente
- Todas las variables agregadas (conteos, promedios por tipo de prueba)
- **Sin valores nulos** - Datos completamente limpios desde la base de datos
- Guardado como CSV con timestamp en `./data/dataset_modelado_YYYYMMDD_HHMMSS.csv`
- **Manejo robusto de NaN** - Valores `nan` de SQL se convierten autom√°ticamente a 0.0

**Flujo recomendado:**

1. Cargar datos desde Excel: `POST /laboratorio/datos`
2. Ejecutar limpieza: `PUT /laboratorio/procesamiento/limpieza`
3. Generar dataset: `GET /laboratorio/dataset/modelado`

**Query SQL - Load (Generaci√≥n del dataset final):**

```sql
WITH paciente_consultas AS (
    SELECT
        p.id_paciente,
        COUNT(c.id_consulta) as count_consultas
    FROM paciente p
    LEFT JOIN consulta c ON p.id_paciente = c.id_paciente
    GROUP BY p.id_paciente
),
paciente_labs AS (
    SELECT
        p.id_paciente,
        COUNT(l.id_lab) as count_laboratorios,
        COALESCE(AVG(l.resultado_numerico), 0) as avg_resultado_numerico,
        COALESCE(AVG(CASE WHEN LOWER(l.tipo_prueba) LIKE '%biopsia%' THEN l.resultado_numerico END), 0) as avg_biopsia,
        COALESCE(AVG(CASE WHEN LOWER(l.tipo_prueba) LIKE '%vph%' THEN l.resultado_numerico END), 0) as avg_vph,
        COALESCE(AVG(CASE WHEN LOWER(l.tipo_prueba) LIKE '%ca125%' OR LOWER(l.tipo_prueba) LIKE '%marcador%' THEN l.resultado_numerico END), 0) as avg_marcador_ca125,
        COALESCE(AVG(CASE WHEN LOWER(l.tipo_prueba) LIKE '%psa%' THEN l.resultado_numerico END), 0) as avg_psa,
        COALESCE(AVG(CASE WHEN LOWER(l.tipo_prueba) LIKE '%colonoscopia%' THEN l.resultado_numerico END), 0) as avg_colonoscopia
    FROM paciente p
    LEFT JOIN laboratorio l ON p.id_paciente = l.id_paciente
    GROUP BY p.id_paciente
)
SELECT
    p.sexo,
    p.edad,
    COALESCE(p.zona_residencia, 'Desconocida') as zona_residencia,
    p.tipo_cancer,
    p.estadio,
    p.aseguradora,
    COALESCE(pc.count_consultas, 0) as count_consultas,
    CURRENT_DATE - p.fecha_dx as dias_desde_diagnostico,
    COALESCE(pl.count_laboratorios, 0) as count_laboratorios,
    COALESCE(pl.avg_resultado_numerico, 0) as avg_resultado_numerico,
    COALESCE(pl.avg_biopsia, 0) as avg_biopsia,
    COALESCE(pl.avg_vph, 0) as avg_vph,
    COALESCE(pl.avg_marcador_ca125, 0) as avg_marcador_ca125,
    COALESCE(pl.avg_psa, 0) as avg_psa,
    COALESCE(pl.avg_colonoscopia, 0) as avg_colonoscopia,
    CASE WHEN p.adherencia_12m THEN 1 ELSE 0 END as adherencia_12m
FROM paciente p
LEFT JOIN paciente_consultas pc ON p.id_paciente = pc.id_paciente
LEFT JOIN paciente_labs pl ON p.id_paciente = pl.id_paciente
WHERE p.sexo IS NOT NULL
  AND p.tipo_cancer IS NOT NULL
  AND p.estadio IS NOT NULL
  AND p.aseguradora IS NOT NULL
ORDER BY p.id_paciente;
```

**Respuesta:**

```json
{
  "ruta_archivo": "./data/dataset_modelado_YYYYMMDD_HHMMSS.csv",
  "total_registros": 1000,
  "descripcion": "Dataset consolidado con 1000 pacientes. Incluye: datos demogr√°ficos, cl√≠nicos, conteos de consultas/laboratorios, y promedios de resultados por tipo de prueba. Listo para modelado de Machine Learning."
}
```

---

### **Parte 2: Machine Learning**

#### **a) Entrenamiento de modelos**

**Endpoint:** `POST /laboratorio/modelado/entrenar`

```bash
# Entrenar modelo XGBoost (Gradient Boosting)
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "xgboost"}'

# Entrenar modelo de Red Neuronal (TensorFlow)
curl -X POST "http://localhost:8000/laboratorio/modelado/entrenar" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{"tipo_modelo": "neural_network"}'
```

**Descripci√≥n:** Entrena modelos de predicci√≥n de adherencia:

- **XGBoost**: Modelo basado en HistGradientBoostingClassifier de scikit-learn
- **Neural Network**: Red neuronal profunda con TensorFlow/Keras

**Proceso autom√°tico:**

1. Carga del dataset m√°s reciente de `./data/`
2. Codificaci√≥n de variables categ√≥ricas (Label Encoding)
3. Split 80/20 (entrenamiento/test)
4. Entrenamiento del modelo
5. Evaluaci√≥n con m√©tricas est√°ndar
6. Guardado autom√°tico en `./models/` con timestamp

**Respuesta:** M√©tricas completas del modelo

```json
{
  "modelo": "xgboost",
  "metricas_train": {
    "accuracy": 0.95,
    "precision": 0.94,
    "recall": 0.96,
    "f1_score": 0.95,
    "auc": 0.97
  },
  "metricas_test": {
    "accuracy": 0.92,
    "precision": 0.91,
    "recall": 0.93,
    "f1_score": 0.92,
    "auc": 0.94
  },
  "tiempo_entrenamiento": 45.23,
  "total_registros": 1000,
  "features_utilizados": 14,
  "fecha_entrenamiento": "2024-11-17T23:12:43"
}
```

---

#### **b) Predicci√≥n de adherencia**

**Endpoint:** `POST /laboratorio/predecir`

```bash
curl -X POST "http://localhost:8000/laboratorio/predecir" \
     -H "accept: application/json" \
     -H "Content-Type: application/json" \
     -d '{
  "tipo_modelo": "xgboost",
  "sexo": "Femenino",
  "edad": 55,
  "zona_residencia": "Urbana",
  "tipo_cancer": "Mama",
  "estadio": "Ii",
  "aseguradora": "Sura",
  "count_consultas": 12,
  "dias_desde_diagnostico": 365,
  "count_laboratorios": 8,
  "avg_resultado_numerico": 2.5,
  "avg_biopsia": 0.0,
  "avg_vpH": 0.0,
  "avg_marcador_ca125": 45.3,
  "avg_psa": 0.0,
  "avg_colonoscopia": 0.0
}'
```

**Descripci√≥n:** Predice la adherencia a 12 meses de un paciente usando el modelo especificado.

**Par√°metros:**

- `tipo_modelo`: `"xgboost"` o `"neural_network"`
- Datos demogr√°ficos: sexo, edad, zona_residencia
- Datos cl√≠nicos: tipo_cancer, estadio, aseguradora
- Variables agregadas: conteos de consultas/laboratorios, promedios de resultados

**Respuesta:**

```json
{
  "prediction": 1,
  "probability": 0.87,
  "model_version": "xgboost_20241117_231152",
  "model_name": "xgboost",
  "inference_time_ms": 15.43
}
```

- `prediction`: 0 = No adherente, 1 = Adherente
- `probability`: Probabilidad de adherencia (0.0 a 1.0)

---

#### **c) Evaluaci√≥n con m√©tricas t√©cnicas**

Las m√©tricas de **accuracy, precision, recall, F1-Score y AUC** se calculan autom√°ticamente durante el entrenamiento y se retornan en la respuesta del endpoint `POST /laboratorio/modelado/entrenar`. Cada modelo incluye m√©tricas tanto para el conjunto de entrenamiento (`metricas_train`) como para el conjunto de test (`metricas_test`).

---

#### **d) Comparaci√≥n de Modelos**

**Resultados del entrenamiento (80 registros: 64 train, 16 test, datos limpios):**

| M√©trica | XGBoost | Neural Network |
|---------|---------|----------------|
| **Accuracy** | **81.25%** | 68.75% |
| **Precision** | **0.7857** | 0.75 |
| **Recall** | **1.0** | 0.8182 |
| **F1-Score** | **0.88** | 0.7826 |
| **AUC-ROC** | **0.6** | 0.6545 |
| Tiempo Entrenamiento | **0.12s** | 2.6s |
| Inference Time | **~5ms** | ~15ms |

**¬øCu√°l funciona mejor?**

**XGBoost** este modelo destaca en recall perfecto (100%) y un accuracy sobre 80%, identificando correctamente todos los pacientes con riesgo de abandono. Sin embargo, su precision moderada (78.57%) genera algunos falsos positivos. La red neuronal muestra mejor AUC (0.6545 vs 0.6), sugiriendo mayor capacidad discriminativa, pero sacrifica accuracy (68.75% vs 81.25%).

**Limitaciones detectadas:**

- **M√©trica faltante cr√≠tica:** No se calcul√≥ **Balanced Accuracy**, esencial para datasets desbalanceados como este (adherencia m√©dica).
- **Dataset peque√±o:** Solo 80 registros limitan la capacidad de generalizaci√≥n de ambos modelos.
- **AUC moderado:** XGBoost (0.6) vs Red Neuronal (0.6545) sugieren necesidad de m√°s features cl√≠nicas.

**Impacto de la limpieza de datos:**

- XGBoost mejor√≥ de 68% a **81.25%** (+13%) gracias a la imputaci√≥n de NaN
- Neural Network mejor√≥ de 31% a **68.75%** (+37%) al eliminar valores faltantes

**¬øCu√°l es m√°s f√°cil de desplegar?**

**XGBoost** es la opci√≥n clara para producci√≥n m√©dica:

- **Simplicidad:** 1 archivo `.pkl` (~100KB) vs modelo `.keras` + scaler `.pkl`
- **Rendimiento:** 3x m√°s r√°pido en inferencia cr√≠tica (5ms vs 15ms)
- **Recursos:** ~50MB RAM vs ~200MB RAM
- **Fiabilidad:** Sin dependencias complejas de GPU/TPU

**Arquitecturas utilizadas:**

**XGBoost (HistGradientBoostingClassifier):**

- **Algoritmo:** Histogram-based gradient boosting
- **Par√°metros:** max_iter=100, max_depth=6, learning_rate=0.1
- **Features:** 11 (edad, consultas, laboratorios, promedios marcadores, zona_residencia_encoded, tipo_cancer_encoded)

**Red Neuronal (TensorFlow Sequential):**

- **Arquitectura:** 64 ‚Üí 32 ‚Üí 16 neuronas con Dropout (0.3, 0.2)
- **Optimizador:** Adam (lr=0.001)
- **Entrenamiento:** 50 epochs, batch_size=32
- **Features:** 11 (mismas que XGBoost)

**Recomendaci√≥n:** **XGBoost** es la opci√≥n recomendada para producci√≥n m√©dica inmediata. Su recall perfecto (100%) asegura que ning√∫n paciente con riesgo de abandono pase desapercibido, compensando su menor precisi√≥n. La velocidad de entrenamiento (0.12s vs 2.6s) lo hace ideal para re-entrenamiento frecuente con nuevos datos m√©dicos.

---

### **Parte 3: An√°lisis y Visualizaci√≥n**

#### **Dashboard por tipo de c√°ncer**

**Endpoint:** `GET /laboratorio/dashboard/{tipo_cancer}`

```bash
curl -X GET "http://localhost:8000/laboratorio/dashboard/Mama" \
     -H "accept: application/json"
```

**Descripci√≥n:** Retorna estad√≠sticas agregadas para un tipo espec√≠fico de c√°ncer:

- Total de pacientes
- Distribuci√≥n por estadio
- Tasa de adherencia
- Promedios de edad
- Distribuci√≥n por aseguradora
- Estad√≠sticas de consultas y laboratorios

---

#### **Pacientes con actividad reciente**

**Endpoint:** `GET /laboratorio/pacientes/activos`

```bash
curl -X GET "http://localhost:8000/laboratorio/pacientes/activos?dias=30" \
     -H "accept: application/json"
```

**Descripci√≥n:** Lista pacientes con consultas o laboratorios en los √∫ltimos N d√≠as.

---

#### **An√°lisis de laboratorios por paciente**

**Endpoint:** `GET /laboratorio/analisis/paciente/{id_paciente}`

```bash
curl -X GET "http://localhost:8000/laboratorio/analisis/paciente/PAC001" \
     -H "accept: application/json"
```

**Descripci√≥n:** An√°lisis detallado de resultados de laboratorio de un paciente espec√≠fico.

### **Parte 4: Despliegue y Arquitectura**

#### **a) Arquitectura de la API de predicci√≥n**

La arquitectura implementada sigue una estructura modular con separaci√≥n clara de responsabilidades:

**i. Almacenamiento:**
**PostgreSQL 17**: Base de datos relacional con esquema definido por SQLModel
**Vol√∫menes persistentes**: Datos de PostgreSQL y modelos ML guardados en contenedores
**Estructura de tablas**: `paciente`, `consulta`, `laboratorio` con relaciones normalizadas

**ii. Pipeline ETL:**
**Carga**: Endpoint `POST /laboratorio/datos` para subir archivos Excel
**Transformaci√≥n**: Endpoint `PUT /laboratorio/procesamiento/limpieza` ejecuta limpieza autom√°tica
**Validaci√≥n**: Tipos de datos, normalizaci√≥n categ√≥rica, imputaci√≥n de valores faltantes
**Salida**: Dataset limpio generado autom√°ticamente en `./data/`

**iii. Entrenamiento:**
**Endpoint**: `POST /laboratorio/modelado/entrenar` con par√°metro `tipo_modelo`
**Modelos**: XGBoost (recomendado) y Red Neuronal TensorFlow
**Guardado**: Modelos serializados en `./models/` con timestamp y metadata
**M√©tricas**: Accuracy, Precision, Recall, F1-Score, AUC calculadas autom√°ticamente

**iv. Endpoint para inferencia:**
**Endpoint**: `POST /laboratorio/predecir` con features del paciente
**Procesamiento**: Codificaci√≥n autom√°tica de variables categ√≥ricas
**Respuesta**: Predicci√≥n binaria (0/1), probabilidad y tiempo de inferencia
**Versionado**: Cada modelo incluye timestamp y versi√≥n en metadata

**v. Monitoreo:**
**Health checks**: Endpoint `/health` con verificaci√≥n de conectividad
**M√©tricas de predicci√≥n**: Tiempo de respuesta, estado √©xito/error
**Logs estructurados**: Archivo `logs/app.log` con niveles DEBUG/INFO
**Docker health checks**: Verificaci√≥n autom√°tica de servicios

**vi. Logs:**
**Consola**: Nivel INFO para operaciones normales
**Archivo**: Nivel DEBUG con rotaci√≥n autom√°tica
**Estructura**: JSON con campos timestamp, level, message, request_id
**Monitoreo de predicciones**: Cada inferencia se registra autom√°ticamente

#### **b) Dockerfile para empaquetar el modelo**

```dockerfile
FROM python:3.13-slim

ENV PYTHONUNBUFFERED=1 \
    PYTHONDONTWRITEBYTECODE=1 \
    PYTHONPATH=/app/src \
    PYTHONHASHSEED=random

RUN apt-get update && \
    apt-get install -y --no-install-recommends \
    libpq5 postgresql-client curl \
    && rm -rf /var/lib/apt/lists/*

RUN useradd -m -u 1000 appuser && \
    mkdir -p /app /app/models /app/logs /app/data && \
    chown -R appuser:appuser /app

WORKDIR /app

COPY --chown=appuser:appuser pyproject.toml ./
RUN pip install --no-cache-dir uv
RUN uv pip install --system --no-cache -r pyproject.toml

COPY --chown=appuser:appuser src/ ./src/
COPY --chown=appuser:appuser alembic/ ./alembic/
COPY --chown=appuser:appuser alembic.ini ./
COPY --chown=appuser:appuser entrypoint.sh ./

RUN chmod +x /app/entrypoint.sh
RUN mkdir -p /app/models /app/logs /app/data && \
    chown -R appuser:appuser /app

USER appuser
EXPOSE 8000

HEALTHCHECK --interval=30s --timeout=10s --start-period=40s --retries=3 \
    CMD python -c "import urllib.request; urllib.request.urlopen('http://localhost:8000/health', timeout=5)" || exit 1

ENTRYPOINT ["/app/entrypoint.sh"]
```

#### **c) Supervisi√≥n, actualizaci√≥n y CI/CD**

**Supervisi√≥n del desempe√±o del modelo:**
**M√©tricas autom√°ticas**: Accuracy, F1-Score calculadas en cada predicci√≥n vs conjunto de test
**Drift detection**: Monitoreo de distribuci√≥n de features de entrada
**Alertas**: Umbrales configurables para degradaci√≥n de performance
**Logging de predicciones**: Cada inferencia se registra con resultado y confianza

**Actualizaci√≥n del modelo:**
**Pipeline automatizado**: Workflow GitHub Actions ejecuta re-entrenamiento semanal
**Validaci√≥n A/B**: Comparaci√≥n de versiones nuevas vs producci√≥n antes de deploy
**Rollback autom√°tico**: Si nueva versi√≥n tiene performance < 95% de la actual
**Notificaci√≥n**: Alertas Slack/email cuando se actualiza modelo en producci√≥n

**Incorporaci√≥n del CI/CD:**
**GitHub Actions**: Pipeline completo con linting (ruff), type checking (pyright), tests
**Build autom√°tico**: Docker image generada y publicada en ghcr.io
**Deploy**: Actualizaci√≥n autom√°tica de contenedores en staging/production
**Versionado sem√°ntico**: Tags v1.2.3 para releases estables

**Kubeflow para MLOps avanzado:**
**Plataforma ideal** para este caso m√©dico por su integraci√≥n nativa con Kubernetes
**Pipelines automatizados** para re-entrenamiento m√©dico con datos sensibles
**Experiment tracking** y model versioning nativos para compliance regulatorio
**Multi-tenancy** perfecta para equipos cl√≠nicos y de desarrollo separados

---

### **Parte 5: Visualizaci√≥n y anal√≠tica**

#### **Dashboard ejecutivo de anal√≠tica oncol√≥gica**

La API incluye endpoints para generar dashboards comprehensivos que permiten visualizar los KPIs clave del programa oncol√≥gico:

##### Dashboard principal - Panorama general

![Dashboard Principal](img/Captura%20de%20pantalla%202025-11-18%20a%20las%200.21.07%20(2).png)

*Vista general con m√©tricas principales

##### Dashboard de adherencia y seguimiento

![Dashboard Adherencia](img/Captura%20de%20pantalla%202025-11-18%20a%20las%200.21.17%20(2).png)

*An√°lisis detallado de adherencia al tratamiento:*

- **Tasa de adherencia** por grupo demogr√°fico (barras agrupadas)
- **Promedio de resultados** por tipo de laboratorio (l√≠neas)
- **Alertas de pacientes** sin seguimiento reciente (lista)
- **Distribuci√≥n por aseguradora** (barras apiladas)

#### **KPIs para equipo directivo**

**Indicadores estrat√©gicos principales:**

- **Tasa de adherencia global**: Meta >80%, indicador de efectividad del programa
- **Cobertura de diagn√≥stico temprano**: % pacientes detectados en estadio I-II
- **Tiempo diagn√≥stico-tratamiento**: <30 d√≠as promedio
- **Reducci√≥n de costos**: Comparaci√≥n costos evitados vs invertidos

**Indicadores operativos clave:**

- **Utilizaci√≥n de servicios**: Consultas por especialidad vs capacidad instalada
- **Tasa de abandono**: Pacientes que dejan el tratamiento antes de 6 meses
- **Efectividad de laboratorios**: % resultados cr√≠ticos identificados oportunamente
- **Satisfacci√≥n del paciente**: Encuestas de experiencia (meta por implementar)

#### **Tipos de visualizaci√≥n y justificaci√≥n**

**Indicadores clave (KPIs Cards):**

- **M√©tricas principales**: N√∫meros grandes y visibles con indicadores de tendencia
- **Por qu√©**: Llaman la atenci√≥n inmediata, facilitan toma de decisiones r√°pida

**Barras (Bar Charts):**

- **Total pacientes por tipo de c√°ncer**: Comparaci√≥n clara entre categor√≠as
- **Adherencia por grupo**: Facilita identificaci√≥n de segmentos de alto riesgo
- **Por qu√©**: F√°cil interpretaci√≥n, comparaci√≥n directa, est√°ndar en reportes ejecutivos

**L√≠neas (Line Charts):**

- **Consultas por mes**: Muestra tendencias temporales y estacionalidad
- **Promedio resultados laboratorio**: Evoluci√≥n de indicadores de salud
- **Por qu√©**: Excelente para detectar patrones, cambios y tendencias a lo largo del tiempo

**Tablas (Data Tables):**

- **Listado de pacientes cr√≠ticos**: Detalles espec√≠ficos con filtros
- **Resumen de KPIs**: Valores exactos con comparaciones
- **Por qu√©**: Precisi√≥n num√©rica, capacidad de drill-down, exportaci√≥n de datos

**Justificaci√≥n general:**

- **Simplicidad**: Mantener visualizaciones claras para ejecutivos no t√©cnicos
- **Accionabilidad**: Cada gr√°fico responde preguntas espec√≠ficas de negocio
- **Consistencia**: Etiquetas claras

---

### **Sistema de anal√≠tica para identificar patrones de uso de servicios entre pacientes oncol√≥gicos**

**i. ¬øQu√© datos usar√≠a?**

Usar√≠a los tres datasets proporcionados:

- **Pacientes.csv**: Para segmentar por caracter√≠sticas demogr√°ficas (edad, tipo_cancer, estadio, aseguradora)
- **Consultas.csv**: Es el dato clave de "uso". Se analizar√≠an los motivos (Quimioterapia, Radioterapia, Cirug√≠a, etc.)
- **Laboratorios.csv**: Como un tipo de servicio adicional (Biopsias, Marcadores tumorales, etc.)

**ii. ¬øC√≥mo los limpiar√≠a?**

- **Nulos**: Rellenar zona_residencia y aseguradora (ej. con "Desconocido" o la moda)
- **Formato**: Convertir todas las columnas de fechas (fecha_dx, fecha_consulta, fecha_muestra) a formato datetime
- **Coherencia**: Estandarizar valores categ√≥ricos (ej. "Pulm√≥n" vs "pulmon", "M" vs "Masculino")

**iii. ¬øC√≥mo estructurar√≠a un modelo o an√°lisis?**

- **Feature Engineering**: Agregar datos a nivel de paciente (id_paciente). Crear variables como total_consultas, n_quimioterapias, n_radioterapias, n_biopsias, tiempo_desde_diagnostico, etc.
- **Modelo (Clustering)**: Aplicar algoritmo no supervisado como K-Means sobre los datos agregados
- **An√°lisis**: El modelo agrupar√≠a pacientes en "cl√∫steres". Cada cl√∫ster representar√≠a un patr√≥n (ej. "Patr√≥n 1: Alto uso de Quimioterapia y Laboratorios", "Patr√≥n 2: Enfoque Quir√∫rgico y Control")

**iv. ¬øQu√© producto final entregar√≠a?**

Un **Dashboard Interactivo** (ej. en Power BI o Tableau) que permita a la direcci√≥n:

- Visualizar los patrones de uso encontrados (ej. gr√°fico de pastel con los cl√∫steres)
- Filtrar estos patrones por tipo de c√°ncer, estadio o aseguradora
- Entender las caracter√≠sticas de cada patr√≥n (ej. qu√© servicios consume cada cl√∫ster)
- Generar reportes autom√°ticos de insights operativos

**v. ¬øQu√© riesgos t√©cnicos anticipar√≠a?**

- **Calidad de Datos**: El principal riesgo. Si los datos de origen (ej. motivo de consulta) se registran mal, el an√°lisis ser√° incorrecto ("Garbage In, Garbage Out")
- **Privacidad**: Manejo de datos sensibles de pacientes (Habeas Data), requiriendo anonimizaci√≥n y controles de acceso estrictos
- **Escalabilidad**: El an√°lisis de clustering puede volverse lento y costoso si los datos crecen de miles a millones de registros

---

## Documentaci√≥n Interactiva

Una vez iniciada la API, accede a:

- **Swagger UI**: <http://localhost:8000/docs>
- **Health Check**: <http://localhost:8000/health>

---

## Arquitectura del Proyecto

```bash
Test-INC/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ main.py                    # Aplicaci√≥n principal FastAPI
‚îÇ   ‚îú‚îÄ‚îÄ models/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ tables.py              # Modelos SQLModel (ORM)
‚îÇ   ‚îú‚îÄ‚îÄ routes/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # Endpoints de datos y procesamiento
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ inference.py           # Endpoints de ML y predicci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ services/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # L√≥gica de procesamiento de datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py           # L√≥gica de ML y predicci√≥n
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.py          # Monitoreo de predicciones
‚îÇ   ‚îú‚îÄ‚îÄ app_types/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ data.py                # Tipos para datos
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ inference.py           # Tipos para ML
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ monitoring.py          # Tipos para monitoreo
‚îÇ   ‚îî‚îÄ‚îÄ utils/
‚îÇ       ‚îú‚îÄ‚îÄ settings.py            # Configuraci√≥n y variables de entorno
‚îÇ       ‚îî‚îÄ‚îÄ logging_config.py      # Configuraci√≥n de logging
‚îú‚îÄ‚îÄ alembic/                       # Migraciones de base de datos
‚îú‚îÄ‚îÄ models/                        # Modelos ML entrenados (*.pkl, *.keras)
‚îú‚îÄ‚îÄ data/                          # Datasets generados (*.csv)
‚îú‚îÄ‚îÄ logs/                          # Logs de la aplicaci√≥n
‚îú‚îÄ‚îÄ docker-compose.yml             # Configuraci√≥n Docker Compose
‚îú‚îÄ‚îÄ Dockerfile                     # Imagen Docker de la API
‚îú‚îÄ‚îÄ entrypoint.sh                  # Script de inicio (ejecuta migraciones)
‚îî‚îÄ‚îÄ pyproject.toml                 # Dependencias del proyecto
```

---

## üîß Stack Tecnol√≥gico

### Backend

- **FastAPI** 0.115+: Framework web moderno y r√°pido
- **Python** 3.13: Lenguaje de programaci√≥n
- **SQLModel**: ORM para PostgreSQL
- **Pydantic**: Validaci√≥n de datos
- **Alembic**: Migraciones de base de datos

### Machine Learning

- **scikit-learn**: Preprocesamiento y XGBoost
- **TensorFlow/Keras**: Redes Neuronales
- **pandas**: Manipulaci√≥n de datos
- **numpy**: Computaci√≥n num√©rica

### Base de Datos

- **PostgreSQL** 17: Base de datos relacional
- **psycopg3**: Driver de PostgreSQL

### DevOps

- **Docker**: Contenedorizaci√≥n
- **Docker Compose**: Orquestaci√≥n de servicios
- **uv**: Gestor de paquetes de Python

---
